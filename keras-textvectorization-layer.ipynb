{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextVectorization Layer Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TextVectorization layer is a text preprocessing layer. This layer maps text features to integer sequences.\n",
    "\n",
    "Here is how to call the TextVectorization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-28 20:17:24.065618: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7fdaaa2f2ee0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.TextVectorization(\n",
    "    max_tokens=None,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=None,\n",
    "    pad_to_max_tokens=False,\n",
    "    vocabulary=None,\n",
    "    idf_weights=None,\n",
    "    sparse=False,\n",
    "    ragged=False,\n",
    "    # **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer transforms a batch of strings(one observation = one string) into either a list of token indices (one observation = 1D tensor of integer token indeces) or a dense representation (one observation = 1D tensor float values representing data about the observation's tokens).\n",
    "\n",
    "This layer is meant to handle natural language inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vocabulary for the TextVectorization layer must be either supplied on construction or learned via `adapt()`. After adaption, the dataset is analyzed. It will determine the frequency of indiviual string values and create a vocabulary for them.\n",
    "\n",
    "You can make the vocabulary unlimited or limit the amount.\n",
    "\n",
    "If there are more unique values in the input than the vocabulary, the most frequent vocabulary will proceed.\n",
    "\n",
    "Here is the preprocessing steps:\n",
    "\n",
    "1. Standardize each observation (lowercase & punctuation stripping)\n",
    "2. Split each observation into substrings (words)\n",
    "3. Recombine substrings into tokens (ngrams)\n",
    "4. Index tokens (assign unique integer value to each token)\n",
    "5. Transform each observation using this index, either into a vector of integers or a dense float vector.\n",
    "\n",
    "#### Some notes on passing callables to customize splitting and normalization for this layer.\n",
    "1. When using a custom callable for `standardize` the data received by the callable will be exactly as passed to this layer. The callable should return a tensor of the same shape as the input.\n",
    "2. When using a custom callable for `split`, the data received by the callable will have the 1st dimension squeezed out - instead of [['string to split'], ['another string to split']], the callable will see ['string to split', 'another string to split']. The callable should return a Tensor with the first dimension containing the split tokens = in this example, we should see something like [['string', 'to', 'split'], ['another', 'string', 'to', 'split']]. This makes the callable site natively compatible with `tf.strings.split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
